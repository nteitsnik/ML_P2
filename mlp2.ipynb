{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79cb0d1-aebc-4784-b109-9b264a511b8e",
   "metadata": {},
   "source": [
    "Import Packages,data and download stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5369e4e7-a7f6-4f11-abc3-e0494440d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nteit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nteit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import tqdm\n",
    "import pprint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.data.path.append(r'C:/nltk_data')\n",
    "\n",
    "\n",
    "\n",
    "fake_news = pd.read_csv(r'C:\\Users\\Nteit\\Downloads\\Fake\\Fake.csv')\n",
    "true_news = pd.read_csv(r'C:\\Users\\Nteit\\Downloads\\True\\True.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19c2ec-d738-4adc-a8b1-8bf7db35aa36",
   "metadata": {},
   "source": [
    "Drop rows with empty news text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf08ab8b-8e47-4f96-a6f3-e95398ccb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news=fake_news.drop(fake_news[fake_news['text']==' '].index,axis=0)\n",
    "true_news=true_news.drop(true_news[true_news['text']==' '].index,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ff7fe-8a82-4560-a081-bb963559a18b",
   "metadata": {},
   "source": [
    "Browse top 5 of entries of fake and true news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8829dc9-b410-4d25-b55c-72c5efc82b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3219b1a0-51d1-4743-bc9a-9eb002832488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a16f3-0e17-47a1-8d3d-bf932541445a",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbf9fa87-65b0-40c0-a8e1-f5c0b74b86e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1201fc3a-9273-4d5f-a3b3-e52fb91fb3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_news['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606be55-1673-4a3e-939f-9d69ea755970",
   "metadata": {},
   "source": [
    "Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a4d8ec6-9c8f-4f5d-9658-ba8e9492b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news['Class']=1\n",
    "true_news['Class']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9594c-9428-4e72-b67a-7b4bd52b3a2f",
   "metadata": {},
   "source": [
    "Remove the Reueters tag and back from real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12f4cfe1-b268-4821-a2db-bf0aa7a90b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_news[\"text\"] = true_news[\"text\"].str.replace(r\".*?\\(Reuters\\) -\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8f757-799b-471e-aa8b-9047410af81b",
   "metadata": {},
   "source": [
    "Create a unified dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5b92713-2c8c-462e-acd0-a03874ad5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=fake_news.columns.values\n",
    "cols=np.append(cols,'Class')\n",
    "news=pd.DataFrame(columns=cols)\n",
    "news=pd.concat([fake_news,true_news])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "144e93ab-f37d-4f07-9bd6-efca8300a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       title   text  subject   date\n",
      "Class                              \n",
      "0      21416  21416    21416  21416\n",
      "1      22855  22855    22855  22855\n"
     ]
    }
   ],
   "source": [
    "print(news.groupby('Class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b8f11-d7ec-4656-8eea-87076134ee89",
   "metadata": {},
   "source": [
    "Keep only text and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fddf07e-4895-45fb-9941-eac3f5e7f8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Class\n",
       "0  Donald Trump just couldn t wish all Americans ...      1\n",
       "1  House Intelligence Committee Chairman Devin Nu...      1\n",
       "2  On Friday, it was revealed that former Milwauk...      1\n",
       "3  On Christmas day, Donald Trump announced that ...      1\n",
       "4  Pope Francis used his annual Christmas Day mes...      1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=news[['text','Class']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aee69-95e2-4796-8e60-7e517b4c388c",
   "metadata": {},
   "source": [
    "Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "457af070-a208-45a3-9d6a-abac1a49ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nteit\\AppData\\Local\\Temp\\ipykernel_2828\\1782702889.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text']=data['text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "data['text']=data['text'].str.lower()\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3ded4-b4df-42cf-b66c-4fe348f4a4a5",
   "metadata": {},
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f225d9b1-35c8-4f11-80ed-5c52d3504aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "        text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in square brackets\n",
    "        text = re.sub(r\"\\\\W\", \" \", text)  # Remove non-word characters\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "        text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6906e7f-080a-4047-9b58-e613c9c06881",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5195d-2ed4-440b-8244-fb77f9495d77",
   "metadata": {},
   "source": [
    "Create a copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83211d4f-8839-460a-9e31-d877719f64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata=pd.DataFrame(columns=['text','Class'])\n",
    "for i in range(len(data)):\n",
    "    textdata.loc[i,'text'] = data.loc[i,'text']\n",
    "    textdata.loc[i,'Class']=int(data.iloc[i, data.columns.get_loc('Class')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b1aae-474e-4dbe-9265-25ca27c9225b",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71492e0d-d952-441d-b0c4-134bab77c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['tokens'] = textdata['text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9de095-fe5a-4f5c-b81e-3f87b814b63b",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3044517-5e5d-4751-a0b3-1f5e95e40de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2d24b3f-e617-4cc0-b12a-3d927b4c6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['tokens'] = textdata['tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c83f3-48ed-44ce-b9a3-d5b75a11bf68",
   "metadata": {},
   "source": [
    "Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0c8d2323-b993-42d9-b7fb-2c338d0e0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_stemmer(tokens):\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return stemmed_tokens\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3373910c-e421-45d8-ad04-262dbe96a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['tokens'] = textdata['tokens'].apply(text_stemmer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38cbf0-203e-4b46-934d-e0322ec3fbe0",
   "metadata": {},
   "source": [
    "Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42abeadc-df63-4cff-b85f-c85639d885a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata = textdata.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff1f41-4067-437e-ae1b-2d63be5f4936",
   "metadata": {},
   "source": [
    "Reconstruct text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ebf7767c-ed09-4640-92e1-b0034823a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['clean_text'] = textdata['tokens'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c875bc2-47bf-4406-a3e3-bf4f1592419d",
   "metadata": {},
   "source": [
    "Preview clean texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e034aae-25e4-4109-8db3-855a09af795e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>military intelligence programs account for  bi...</td>\n",
       "      <td>militari intellig program account billion pent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us judge james robart emerged from relative ob...</td>\n",
       "      <td>us judg jame robart emerg rel obscur saturday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>century wire says rich men love to gamble over...</td>\n",
       "      <td>centuri wire say rich men love gambl last week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us president donald trump has invited three la...</td>\n",
       "      <td>us presid donald trump invit three latin ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the pentagon plans to transfer about a dozen i...</td>\n",
       "      <td>pentagon plan transfer dozen inmat guantanamo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  military intelligence programs account for  bi...   \n",
       "1  us judge james robart emerged from relative ob...   \n",
       "2  century wire says rich men love to gamble over...   \n",
       "3  us president donald trump has invited three la...   \n",
       "4  the pentagon plans to transfer about a dozen i...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  militari intellig program account billion pent...  \n",
       "1  us judg jame robart emerg rel obscur saturday ...  \n",
       "2  centuri wire say rich men love gambl last week...  \n",
       "3  us presid donald trump invit three latin ameri...  \n",
       "4  pentagon plan transfer dozen inmat guantanamo ...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "textdata[['text','clean_text']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26137c9e-518a-447b-9d39-9c2d6718cc6f",
   "metadata": {},
   "source": [
    "Drop empty rows after cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23727571-903f-4abd-addb-7c393854f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata=textdata.drop(textdata[textdata['clean_text']==''].index,axis=0)\n",
    "textdata = textdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d91462-e336-4fb1-b756-d9861c645412",
   "metadata": {},
   "source": [
    "Create Models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2ecdee9-8971-448e-a8f4-b5380c9032de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_model = LogisticRegression(penalty=None)\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "ridge_model = LogisticRegression(penalty='l2')\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "models=[ MultinomialNB(),logistic_model,lasso_model,ridge_model,dt_classifier,svm.SVC()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554cd640-ce2f-4129-a297-7926f6134e80",
   "metadata": {},
   "source": [
    "Run models for Binary Vectorizer and save results to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13daba31-988d-4e7f-a331-a70367f25875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizers=[CountVectorizer(binary=True)]\n",
    "Y = textdata['Class']\n",
    "resultsdfac=pd.DataFrame()\n",
    "for vectorizer in vectorizers:  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(textdata['clean_text'], Y, test_size=0.2, random_state=2)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "    Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "    for model in models:\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        if model==lasso_model :\n",
    "            resultsdfac.loc['lasso','Binary'] = accuracy_score(Y_test, Y_pred)\n",
    "        elif model==ridge_model:\n",
    "            resultsdfac.loc['ridge','Binary']= accuracy_score(Y_test, Y_pred)\n",
    "        elif  model==logistic_model:\n",
    "            resultsdfac.loc['logistic','Binary'] = accuracy_score(Y_test, Y_pred) \n",
    "        else:\n",
    "            resultsdfac.loc[model.__class__.__name__,'Binary']= accuracy_score(Y_test, Y_pred) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b77ff-ec14-470e-a013-f1e7500f2bda",
   "metadata": {},
   "source": [
    "Run models for Counts Vectorizer,Tfidf and save results to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5a81e2e3-aaa9-4683-b22f-d231760cd8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "vectorizers=[CountVectorizer(binary=False),TfidfVectorizer(max_features=5000)]\n",
    "\n",
    "\n",
    "Y = textdata['Class']\n",
    "\n",
    "for vectorizer in vectorizers:  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(textdata['clean_text'], Y, test_size=0.2, random_state=2)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "    Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "    for model in models:\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        if model==lasso_model :\n",
    "            resultsdfac.loc['lasso',vectorizer.__class__.__name__] = accuracy_score(Y_test, Y_pred)\n",
    "        elif model==ridge_model:\n",
    "            resultsdfac.loc['ridge',vectorizer.__class__.__name__]= accuracy_score(Y_test, Y_pred)\n",
    "        elif  model==logistic_model:\n",
    "            resultsdfac.loc['logistic',vectorizer.__class__.__name__] = accuracy_score(Y_test, Y_pred) \n",
    "        else:\n",
    "            resultsdfac.loc[model.__class__.__name__,vectorizer.__class__.__name__]= accuracy_score(Y_test, Y_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee460af1-9f91-464c-aab7-a66a8b32572f",
   "metadata": {},
   "source": [
    "Run models on word2vec with 300 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "beb2febf-0a25-400c-866f-a43a60344ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def get_average_word2vec(tokens_list, w2vec, vector_size=300):\n",
    "  \n",
    "    # Filter out words not in the Word2Vec vocabulary\n",
    "    valid_words = [w2vec.wv[word] for word in tokens_list if word in w2vec.wv]\n",
    "\n",
    "    # If no valid words, return a zero vector\n",
    "    if not valid_words:\n",
    "        return np.zeros(vector_size)\n",
    "    \n",
    "    # Calculate the mean of valid word vectors\n",
    "    tmp = np.vstack(valid_words)  # Stack vectors vertically\n",
    "    result = np.mean(tmp, axis=0)  # Calculate mean across rows\n",
    "    return result\n",
    "    # If no valid words, return a zero vector of the desired size\n",
    "    \n",
    "logistic_model = LogisticRegression(penalty=None)\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "ridge_model = LogisticRegression(penalty='l2')\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "models=[ logistic_model,lasso_model,ridge_model,dt_classifier,svm.SVC()]  \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(textdata['tokens'], Y, test_size=0.2, random_state=2)\n",
    "w2vec = Word2Vec(sentences=X_train, vector_size=300, window=5, min_count=1, workers=6)\n",
    "\n",
    "\n",
    "\n",
    "Train_trans=np.zeros((len(X_train),300))\n",
    "Test_trans=np.zeros((len(X_test),300))\n",
    "i=0\n",
    "for idx in X_train.index :     \n",
    "    Train_trans[i,:] = get_average_word2vec(X_train[idx], w2vec) \n",
    "    i=i+1\n",
    "       \n",
    "i=0\n",
    "for idx in X_test.index :   \n",
    "    \n",
    "    Test_trans[i,:] = get_average_word2vec(X_test[idx], w2vec) \n",
    "    i=i+1\n",
    "    \n",
    "Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "for model in models:\n",
    "        model.fit(Train_trans, Y_train)\n",
    "        Y_pred = model.predict(Test_trans)\n",
    "        if model==lasso_model :\n",
    "            resultsdfac.loc['lasso','word2vec'] = accuracy_score(Y_test, Y_pred)\n",
    "        elif model==ridge_model:\n",
    "            resultsdfac.loc['ridge','word2vec']= accuracy_score(Y_test, Y_pred)\n",
    "        elif  model==logistic_model:\n",
    "            resultsdfac.loc['logistic','word2vec'] = accuracy_score(Y_test, Y_pred) \n",
    "        else:\n",
    "            resultsdfac.loc[model.__class__.__name__,'word2vec']= accuracy_score(Y_test, Y_pred) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "71eb28f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('presidentelect', 0.5541456937789917), ('trumprush', 0.4533597528934479), ('obama', 0.4419034719467163), ('jtrump', 0.4337442219257355), ('deliveredand', 0.4319506883621216), ('mcgahnthat', 0.42233526706695557), ('actual', 0.4220310151576996), ('assit', 0.4157116711139679), ('visittrump', 0.4130549430847168), ('administrationpresidentelect', 0.4120168089866638)]\n"
     ]
    }
   ],
   "source": [
    "print(w2vec.wv.most_similar('trump'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc587b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth=1) \n",
    "rf_model = AdaBoostClassifier(\n",
    "    base_estimator=base_estimator,\n",
    "    n_estimators=50,  # Number of weak learners\n",
    "    learning_rate=1.0,  # Shrinks the contribution of each weak learner\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "vectorizers=[CountVectorizer(binary=True)]\n",
    "Y = textdata['Class']\n",
    "for vectorizer in vectorizers:  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(textdata['clean_text'], Y, test_size=0.2, random_state=2)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "    Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    Y_pred = rf_model.predict(X_test)       \n",
    "    resultsdfac.loc[rf_model.__class__.__name__,'Binary']= accuracy_score(Y_test, Y_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0d81f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizers=[CountVectorizer(binary=False),TfidfVectorizer(max_features=5000)]\n",
    "\n",
    "\n",
    "Y = textdata['Class']\n",
    "\n",
    "for vectorizer in vectorizers:  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(textdata['clean_text'], Y, test_size=0.2, random_state=2)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "    Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    Y_pred = rf_model.predict(X_test)       \n",
    "    resultsdfac.loc[rf_model.__class__.__name__,vectorizer.__class__.__name__]= accuracy_score(Y_test, Y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97a66538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nteit\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(textdata['tokens'], Y, test_size=0.2, random_state=2)\n",
    "w2vec = Word2Vec(sentences=X_train, vector_size=300, window=5, min_count=1, workers=6)\n",
    "\n",
    "\n",
    "\n",
    "Train_trans=np.zeros((len(X_train),300))\n",
    "Test_trans=np.zeros((len(X_test),300))\n",
    "i=0\n",
    "for idx in X_train.index :     \n",
    "    Train_trans[i,:] = get_average_word2vec(X_train[idx], w2vec) \n",
    "    i=i+1\n",
    "       \n",
    "i=0\n",
    "for idx in X_test.index :   \n",
    "    \n",
    "    Test_trans[i,:] = get_average_word2vec(X_test[idx], w2vec) \n",
    "    i=i+1\n",
    "    \n",
    "Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "rf_model.fit(Train_trans, Y_train)\n",
    "Y_pred = rf_model.predict(Test_trans)\n",
    "resultsdfac.loc[rf_model.__class__.__name__,'word2vec']= accuracy_score(Y_test, Y_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d249faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "vectorizers=[CountVectorizer(binary=True)]\n",
    "Y = textdata['Class']\n",
    "for vectorizer in vectorizers:  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(textdata['clean_text'], Y, test_size=0.2, random_state=2)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "    Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    Y_pred = rf_model.predict(X_test)       \n",
    "    resultsdfac.loc[rf_model.__class__.__name__,'Binary']= accuracy_score(Y_test, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1efec9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers=[CountVectorizer(binary=False),TfidfVectorizer(max_features=5000)]\n",
    "\n",
    "\n",
    "Y = textdata['Class']\n",
    "\n",
    "for vectorizer in vectorizers:  \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(textdata['clean_text'], Y, test_size=0.2, random_state=2)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "    Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    Y_pred = rf_model.predict(X_test)       \n",
    "    resultsdfac.loc[rf_model.__class__.__name__,vectorizer.__class__.__name__]= accuracy_score(Y_test, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7fad2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(textdata['tokens'], Y, test_size=0.2, random_state=2)\n",
    "w2vec = Word2Vec(sentences=X_train, vector_size=300, window=5, min_count=1, workers=6)\n",
    "\n",
    "\n",
    "\n",
    "Train_trans=np.zeros((len(X_train),300))\n",
    "Test_trans=np.zeros((len(X_test),300))\n",
    "i=0\n",
    "for idx in X_train.index :     \n",
    "    Train_trans[i,:] = get_average_word2vec(X_train[idx], w2vec) \n",
    "    i=i+1\n",
    "       \n",
    "i=0\n",
    "for idx in X_test.index :   \n",
    "    \n",
    "    Test_trans[i,:] = get_average_word2vec(X_test[idx], w2vec) \n",
    "    i=i+1\n",
    "    \n",
    "Y_train = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_train)\n",
    "Y_test = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y_test)\n",
    "rf_model.fit(Train_trans, Y_train)\n",
    "Y_pred = rf_model.predict(Test_trans)\n",
    "resultsdfac.loc[rf_model.__class__.__name__,'word2vec']= accuracy_score(Y_test, Y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9551cead-7b83-4a58-b5e8-7243907b2c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Binary  CountVectorizer  TfidfVectorizer  word2vec\n",
      "MultinomialNB           0.954859         0.948750         0.922050       NaN\n",
      "logistic                0.987103         0.985971         0.985971  0.970811\n",
      "lasso                   0.987555         0.984501         0.979636  0.970472\n",
      "ridge                   0.989365         0.987103         0.979975  0.969906\n",
      "DecisionTreeClassifier  0.945016         0.943093         0.936192  0.920919\n",
      "SVC                     0.989478         0.980880         0.988347  0.975902\n",
      "AdaBoostClassifier      0.946713         0.949316         0.948863  0.937323\n",
      "RandomForestClassifier  0.974092         0.975563         0.982012  0.964136\n"
     ]
    }
   ],
   "source": [
    "print(resultsdfac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2594f9a-5012-43ee-ada8-2847bea5101f",
   "metadata": {},
   "source": [
    "Grid Search on Logistic Regression for Binary Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f93dfb18-9f63-4933-a77d-8d7029113791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001EB2308A4D0&gt;,\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 500],\n",
       "                                        &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                                   &#x27;sag&#x27;],\n",
       "                                        &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]},\n",
       "                   random_state=2, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001EB2308A4D0&gt;,\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 500],\n",
       "                                        &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                                   &#x27;sag&#x27;],\n",
       "                                        &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]},\n",
       "                   random_state=2, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001EB2308A4D0>,\n",
       "                                        'max_iter': [100, 200, 500],\n",
       "                                        'solver': ['lbfgs', 'saga', 'newton-cg',\n",
       "                                                   'sag'],\n",
       "                                        'tol': [1e-05, 0.0001, 0.001]},\n",
       "                   random_state=2, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "log_reg = LogisticRegression(penalty='l2')\n",
    "param_grid = {\n",
    "    'C': loguniform(1e-4, 1e2),        # Regularization strength\n",
    "    'solver': ['lbfgs', 'saga', 'newton-cg', 'sag'],  # Solvers supporting L2\n",
    "    'max_iter': [100, 200, 500], # Max iterations\n",
    "    'tol': [1e-5, 1e-4, 1e-3]        # Tolerance for convergence\n",
    "   \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of random configurations to try\n",
    "    scoring='accuracy',  # Or another appropriate metric\n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1,  # Use all available processors\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "\n",
    "vectorizer=CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(textdata['clean_text'])\n",
    "Y = textdata['Class']\n",
    "Y = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee08998f-7b4e-4a17-88fc-ddb0607c4a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.4473556706796925, 'max_iter': 100, 'solver': 'newton-cg', 'tol': 1e-05}\n",
      "Best Accuracy: 0.9880752541357308\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Accuracy:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cce584f-b5af-463e-ae7e-07bd9de05ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.4473556706796925, solver=&#x27;newton-cg&#x27;, tol=1e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.4473556706796925, solver=&#x27;newton-cg&#x27;, tol=1e-05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.4473556706796925, solver='newton-cg', tol=1e-05)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(C=0.4473556706796925, solver='newton-cg', tol=1e-05)\n",
    "vectorizer=CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(textdata['clean_text'])\n",
    "Y = textdata['Class']\n",
    "Y = np.vectorize(lambda x: pd.to_numeric(x, errors='coerce'))(Y)\n",
    "model.fit(X, Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054ffd4-505a-45e9-a28e-6aabb3da0393",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "77d15748-776d-413d-99cd-7e0977f6ae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BREAKING: Donald Trump Announces Plan to Colonize Mars Former. President Donald Trump unveiled an ambitious plan today, declaring his intention to lead the charge in colonizing Mars. Speaking at a rally, he stated, “No one’s ever done Mars like we’re going to do it. It’ll be tremendous, believe me.” Trump claimed his new initiative, \"Trump Galactic,\" would establish \"the biggest, most luxurious Martian city ever.\" Critics dismissed the plan as unrealistic, but supporters hailed it as visionary. SpaceX founder Elon Musk declined to comment, fueling speculation about potential collaboration.Stay tuned for developments on this out-of-this-world endeavor. ']\n"
     ]
    }
   ],
   "source": [
    "prompt=['BREAKING: Donald Trump Announces Plan to Colonize Mars Former. President Donald Trump unveiled an ambitious plan today, declaring his intention to lead the charge in colonizing Mars. Speaking at a rally, he stated, “No one’s ever done Mars like we’re going to do it. It’ll be tremendous, believe me.” Trump claimed his new initiative, \"Trump Galactic,\" would establish \"the biggest, most luxurious Martian city ever.\" Critics dismissed the plan as unrealistic, but supporters hailed it as visionary. SpaceX founder Elon Musk declined to comment, fueling speculation about potential collaboration.Stay tuned for developments on this out-of-this-world endeavor. ']\n",
    "dftry=pd.DataFrame(data=prompt,columns=['text'])\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f90bee1-abff-44c3-87cf-820511b61e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftry['text']=dftry['text'].apply(clean_text)\n",
    "dftry['tokens'] = dftry['text'].apply(lambda x: x.split())\n",
    "dftry['tokens'] = dftry['tokens'].apply(remove_stopwords)\n",
    "dftry['tokens'] = dftry['tokens'].apply(text_stemmer)\n",
    "dftry['clean_text'] = dftry['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "X_test = vectorizer.transform(dftry['clean_text'])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7232da33-ba57-477b-814f-d779b3a70db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A former Colorado Bureau of Investigation DNA scientist appeared in court Thursday to face criminal charges over data tampering that authorities said raises questions about the validity of more than 500 cases.Problems with the scientist’s work were found in cases involving homicide, sexual assault, robbery and other crimes, according to a law enforcement affidavit.In at least two cases, both homicides, the defendants received lesser sentences under plea deals than they could have faced if they went to trial because prosecutors were afraid Yvonne “Missy” Woods’ involvement could lead to acquittals.Woods was described as a “star analyst” by a former colleague who was interviewed by investigators, but also one who worked too fast and was “not the most thorough,” according to an internal affairs report.Authorities haven’t found any evidence of wrongful convictions, but prosecutors across the state are continuing to review the impacted cases.“This gets to the heart of whether or not science can be trusted, whether or not law enforcement can be trusted and quite frankly whether the judicial system can be trusted,” Jefferson County judge Graham Peper said during the short hearing.Woods allegedly told investigators at one point that she had changed data to complete cases more quickly, according to an arrest affidavit.Woods faces 52 counts of forgery, 48 counts of attempting to influence a public servant and one count each of perjury and cybercrime, for alleged misconduct between 2008 and 2023.The fallout from the alleged misconduct is still unfolding.In the most recent case to be impacted, Michael Shannel Jefferson was sentenced last week to 32 years in prison in the home invasion killing of Roger Dean in 1985. Jefferson was identified as a suspect in the cold case in 2021 through DNA evidence.']\n"
     ]
    }
   ],
   "source": [
    "prompt=['A former Colorado Bureau of Investigation DNA scientist appeared in court Thursday to face criminal charges over data tampering that authorities said raises questions about the validity of more than 500 cases.Problems with the scientist’s work were found in cases involving homicide, sexual assault, robbery and other crimes, according to a law enforcement affidavit.In at least two cases, both homicides, the defendants received lesser sentences under plea deals than they could have faced if they went to trial because prosecutors were afraid Yvonne “Missy” Woods’ involvement could lead to acquittals.Woods was described as a “star analyst” by a former colleague who was interviewed by investigators, but also one who worked too fast and was “not the most thorough,” according to an internal affairs report.Authorities haven’t found any evidence of wrongful convictions, but prosecutors across the state are continuing to review the impacted cases.“This gets to the heart of whether or not science can be trusted, whether or not law enforcement can be trusted and quite frankly whether the judicial system can be trusted,” Jefferson County judge Graham Peper said during the short hearing.Woods allegedly told investigators at one point that she had changed data to complete cases more quickly, according to an arrest affidavit.Woods faces 52 counts of forgery, 48 counts of attempting to influence a public servant and one count each of perjury and cybercrime, for alleged misconduct between 2008 and 2023.The fallout from the alleged misconduct is still unfolding.In the most recent case to be impacted, Michael Shannel Jefferson was sentenced last week to 32 years in prison in the home invasion killing of Roger Dean in 1985. Jefferson was identified as a suspect in the cold case in 2021 through DNA evidence.']\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c758847a-facb-41d9-b894-80803e32387e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftry=pd.DataFrame(data=prompt,columns=['text'])\n",
    "\n",
    "dftry['text']=dftry['text'].apply(clean_text)\n",
    "dftry['tokens'] = dftry['text'].apply(lambda x: x.split())\n",
    "dftry['tokens'] = dftry['tokens'].apply(remove_stopwords)\n",
    "dftry['tokens'] = dftry['tokens'].apply(text_stemmer)\n",
    "dftry['clean_text'] = dftry['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "X_test = vectorizer.transform(dftry['clean_text'])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e166da37-76c3-4e8a-bc81-64d888d410d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a stunning press announcement, former President Donald Trump declared a \"war on Mars,\" claiming the planet poses a threat to Earth.Mars has been stealing Earth’s energy for years—bad energy, folks,\" Trump stated, without providing evidence. He proposed creating a new military branch, the \"Galactic Space Force,\" to counter this supposed threat.Critics dismissed the claim as science fiction, while supporters praised Trump’s \"bold vision.\" Trump also hinted at secret backing from Elon Musk but offered no details.NASA officials, caught off guard, declined to comment, with one insider joking, \"We’re focused on science, not space wars.\"Trump promised the initiative would be \"tremendous,\" though experts remain skeptical.']\n"
     ]
    }
   ],
   "source": [
    "prompt=['In a stunning press announcement, former President Donald Trump declared a \"war on Mars,\" claiming the planet poses a threat to Earth.Mars has been stealing Earth’s energy for years—bad energy, folks,\" Trump stated, without providing evidence. He proposed creating a new military branch, the \"Galactic Space Force,\" to counter this supposed threat.Critics dismissed the claim as science fiction, while supporters praised Trump’s \"bold vision.\" Trump also hinted at secret backing from Elon Musk but offered no details.NASA officials, caught off guard, declined to comment, with one insider joking, \"We’re focused on science, not space wars.\"Trump promised the initiative would be \"tremendous,\" though experts remain skeptical.']\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "04473fc4-f7fc-4905-8594-9196479b44c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftry=pd.DataFrame(data=prompt,columns=['text'])\n",
    "\n",
    "dftry['text']=dftry['text'].apply(clean_text)\n",
    "dftry['tokens'] = dftry['text'].apply(lambda x: x.split())\n",
    "dftry['tokens'] = dftry['tokens'].apply(remove_stopwords)\n",
    "dftry['tokens'] = dftry['tokens'].apply(text_stemmer)\n",
    "dftry['clean_text'] = dftry['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "X_test = vectorizer.transform(dftry['clean_text'])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fa8f4779-1a85-4ea7-8386-5aaf1f8b1e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In a shocking revelation during a livestream, Kanye West unveiled his latest vision: creating a self-sustaining city called “Yeezy City” in the middle of the Nevada desert. The city, described by Kanye as “the future of human innovation,” will reportedly feature futuristic Yeezy-designed homes, a music production hub, and a museum dedicated entirely to Kanye’s career.Yeezy City will be a utopia where creativity knows no limits,” West stated. He also hinted at plans for a cryptocurrency called “YeezyCoin” to power the local economy.Critics have questioned the feasibility of the project, while fans have already started online petitions to move there. When asked about timelines, Kanye confidently replied, “We’re breaking ground next year. Elon’s already on board.”The announcement has sparked a social media frenzy, with many wondering if Yeezy City could become the next Silicon Valley—or just another Kanye dream.']\n"
     ]
    }
   ],
   "source": [
    "prompt=['In a shocking revelation during a livestream, Kanye West unveiled his latest vision: creating a self-sustaining city called “Yeezy City” in the middle of the Nevada desert. The city, described by Kanye as “the future of human innovation,” will reportedly feature futuristic Yeezy-designed homes, a music production hub, and a museum dedicated entirely to Kanye’s career.Yeezy City will be a utopia where creativity knows no limits,” West stated. He also hinted at plans for a cryptocurrency called “YeezyCoin” to power the local economy.Critics have questioned the feasibility of the project, while fans have already started online petitions to move there. When asked about timelines, Kanye confidently replied, “We’re breaking ground next year. Elon’s already on board.”The announcement has sparked a social media frenzy, with many wondering if Yeezy City could become the next Silicon Valley—or just another Kanye dream.']\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d85f1a9-4153-410c-afda-f86feaa3807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftry['text']=dftry['text'].apply(clean_text)\n",
    "dftry['tokens'] = dftry['text'].apply(lambda x: x.split())\n",
    "dftry['tokens'] = dftry['tokens'].apply(remove_stopwords)\n",
    "dftry['tokens'] = dftry['tokens'].apply(text_stemmer)\n",
    "dftry['clean_text'] = dftry['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "X_test = vectorizer.transform(dftry['clean_text'])\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c456f5cd-111d-4058-b56b-ffdbc0b28650",
   "metadata": {},
   "source": [
    "Check the words that decide the outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e12e2e7-bcb7-456b-9854-a092a52eac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e1eca986-2300-45df-a2f0-70ec53b7d983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top fake news predictors:\n",
      "via: 3.2403\n",
      "sen: 1.8893\n",
      "gop: 1.8139\n",
      "obama: 1.8003\n",
      "rep: 1.7852\n",
      "imag: 1.7586\n",
      "\n",
      "Top real news words:\n",
      "said: -2.3925\n",
      "thursday: -1.7609\n",
      "dont: -1.7605\n",
      "wednesday: -1.7304\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "sorted_coefficients = coefficients[sorted_indices]\n",
    "sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "sorted_feature_names = feature_names[sorted_indices]\n",
    "sorted_coefficients = coefficients[sorted_indices]\n",
    "\n",
    "top_positive_words = [(sorted_feature_names[i], sorted_coefficients[i]) \n",
    "                      for i in range(10) if sorted_coefficients[i] > 0]\n",
    "top_negative_words = [(sorted_feature_names[i], sorted_coefficients[i]) \n",
    "                      for i in range(10) if sorted_coefficients[i] < 0]\n",
    "print(\"Top fake news predictors:\")\n",
    "for word, coef in top_positive_words:\n",
    "    print(f\"{word}: {coef:.4f}\")\n",
    "print(\"\\nTop real news words:\")\n",
    "for word, coef in top_negative_words:\n",
    "    print(f\"{word}: {coef:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93091ee2-72e1-417f-8906-efc62432adb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a36ccb-bf0a-4bb9-8a47-81b35517b982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
